{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e65978e1-8356-4c14-9307-fba2f9f4709b",
   "metadata": {
    "id": "e65978e1-8356-4c14-9307-fba2f9f4709b"
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torchvision\n",
    "import os\n",
    "import cv2\n",
    "import numpy as np\n",
    "from torch import nn\n",
    "from glob import glob\n",
    "import timm\n",
    "import torch.nn.functional as F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b04843cb-0c57-40e8-84e5-30b0d359e0a7",
   "metadata": {
    "id": "b04843cb-0c57-40e8-84e5-30b0d359e0a7"
   },
   "outputs": [],
   "source": [
    "image_paths = './Data/*/*'\n",
    "image_paths = glob(image_paths)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8629ecf4-3d32-4a97-9a18-4c93ce9071e5",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "8629ecf4-3d32-4a97-9a18-4c93ce9071e5",
    "outputId": "6edfa02b-c6c8-43f9-8693-09cafe427eb2"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1944"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(image_paths)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c3574ce6-29bd-434f-a9fb-6c8c59e812e9",
   "metadata": {
    "id": "c3574ce6-29bd-434f-a9fb-6c8c59e812e9"
   },
   "outputs": [],
   "source": [
    "labels = []\n",
    "images = []\n",
    "\n",
    "for image_path in image_paths:\n",
    "    label = image_path.split(os.path.sep)[2]\n",
    "    image = image_path.split(os.path.sep)[3]\n",
    "    labels.append(label)\n",
    "    images.append(image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c6eeb550",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['Cataracts', 'Glaucoma', 'Healthy', 'Uveitis'], dtype='<U9')"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.unique(labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e0ebdcd1-04fd-447a-8ed7-3c07d5f105a4",
   "metadata": {
    "id": "e0ebdcd1-04fd-447a-8ed7-3c07d5f105a4"
   },
   "outputs": [],
   "source": [
    "labels = np.array(labels, dtype='str')\n",
    "label2pred = dict(zip(np.unique(labels), range(0, 4)))\n",
    "pred2label = dict(zip(range(0, 4), np.unique(labels)))\n",
    "n_classes = len(np.unique(labels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b97966d-bdf5-402a-999f-e1d1b771964c",
   "metadata": {
    "id": "2b97966d-bdf5-402a-999f-e1d1b771964c"
   },
   "outputs": [],
   "source": [
    "class IrisDisease(torch.utils.data.Dataset):\n",
    "    \n",
    "    def __init__(self, image_paths, labels, transforms=None):\n",
    "        super(IrisDisease, self).__init__()\n",
    "        \n",
    "        self.image_paths = image_paths\n",
    "        self.labels = labels\n",
    "        self.transforms = transforms\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.image_paths)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        \n",
    "        image = cv2.imread(self.image_paths[idx])\n",
    "        image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
    "        image = cv2.resize(image, (300, 300))\n",
    "            \n",
    "        label = self.labels[idx]\n",
    "        label = label2pred[label]\n",
    "        label = torch.tensor(label)\n",
    "        \n",
    "        if self.transforms:\n",
    "            image = self.transforms(image)\n",
    "        \n",
    "        return image, label        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75edbd36-d771-495a-b3dc-d948224e2a60",
   "metadata": {
    "id": "75edbd36-d771-495a-b3dc-d948224e2a60"
   },
   "outputs": [],
   "source": [
    "device='cpu'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ee90b2c-bab6-4450-95c5-3c64ea6b1169",
   "metadata": {
    "id": "4ee90b2c-bab6-4450-95c5-3c64ea6b1169"
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "train_image_paths, test_image_paths, train_labels, test_labels = train_test_split(image_paths, labels, test_size=0.25, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5bc27969-a651-49e2-bdf9-2c4df7354543",
   "metadata": {
    "id": "5bc27969-a651-49e2-bdf9-2c4df7354543"
   },
   "outputs": [],
   "source": [
    "tr_transforms = torchvision.transforms.Compose([\n",
    "    torchvision.transforms.ToTensor(),\n",
    "    torchvision.transforms.CenterCrop(300),\n",
    "])\n",
    "\n",
    "val_transforms = torchvision.transforms.Compose([\n",
    "    torchvision.transforms.ToTensor(),\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07d11807-e11a-4428-891e-bf0914fbe27f",
   "metadata": {
    "id": "07d11807-e11a-4428-891e-bf0914fbe27f"
   },
   "outputs": [],
   "source": [
    "train_dataset = IrisDisease(image_paths=train_image_paths, labels=train_labels, transforms=tr_transforms)\n",
    "test_dataset = IrisDisease(image_paths=test_image_paths, labels=test_labels, transforms=val_transforms)\n",
    "# train_dataset = Dataset(image_paths=image_paths, label=labels, transforms=torchvision.transforms.ToTensor())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34fb22e8-d7be-43f8-8750-4625a732c188",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "34fb22e8-d7be-43f8-8750-4625a732c188",
    "outputId": "c2861723-fa25-4709-e5c1-186a7eff8831"
   },
   "outputs": [],
   "source": [
    "len(train_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67c29fba-e4d3-47b8-b76f-c7fe41f19034",
   "metadata": {
    "id": "67c29fba-e4d3-47b8-b76f-c7fe41f19034"
   },
   "outputs": [],
   "source": [
    "train_dataloader = torch.utils.data.DataLoader(dataset=train_dataset, batch_size=32, shuffle=True)\n",
    "test_dataloader = torch.utils.data.DataLoader(dataset=test_dataset, batch_size=32, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a31db6b7-0c83-4a31-87a3-975ac8629e4b",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 287
    },
    "id": "a31db6b7-0c83-4a31-87a3-975ac8629e4b",
    "outputId": "0c2340b8-48dc-46af-984d-73c51b4fb496"
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.imshow(train_dataset[10][0].permute(1, 2, 0))\n",
    "print(pred2label[train_dataset[10][1].item()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a72e697d-de15-4fa0-91b0-5601c5fb4c2e",
   "metadata": {
    "id": "a72e697d-de15-4fa0-91b0-5601c5fb4c2e"
   },
   "outputs": [],
   "source": [
    "class ClassificationBase(nn.Module):\n",
    "    def training_step(self, batch):\n",
    "        images, labels = batch\n",
    "        images = images.to(device)\n",
    "        labels = labels.to(device)\n",
    "        out = self(images)\n",
    "        loss = F.cross_entropy(out, labels)\n",
    "        acc = accuracy(out, labels)          \n",
    "        return loss, acc\n",
    "\n",
    "    def validation_step(self, batch):\n",
    "        images, labels = batch \n",
    "        images = images.to(device)\n",
    "        labels = labels.to(device)\n",
    "        out = self(images)                    \n",
    "        loss = F.cross_entropy(out, labels)  \n",
    "        acc = accuracy(out, labels)          \n",
    "        return {'val_loss': loss.detach(), 'val_acc': acc}\n",
    "        \n",
    "    def validation_epoch_end(self, outputs):\n",
    "        batch_losses = [x['val_loss'] for x in outputs]\n",
    "        epoch_loss = torch.stack(batch_losses).mean()   \n",
    "        batch_accs = [x['val_acc'] for x in outputs]\n",
    "        epoch_acc = torch.stack(batch_accs).mean()    \n",
    "        return {'val_loss': epoch_loss.item(), 'val_acc': epoch_acc.item()}\n",
    "    \n",
    "    def epoch_end(self, epoch, result):\n",
    "        print(\"Epoch [{}], val_loss: {:.4f}, val_acc: {:.4f}\".format(epoch, result['val_loss'], result['val_acc']))\n",
    "        \n",
    "\n",
    "def accuracy(outputs, labels):\n",
    "    _, preds = torch.max(outputs, dim=1)\n",
    "    return torch.tensor(torch.sum(preds == labels).item() / len(preds))\n",
    "\n",
    "def evaluate(model, val_loader):\n",
    "    outputs = [model.validation_step(batch) for batch in val_loader]\n",
    "    return model.validation_epoch_end(outputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e6e3793-5270-461f-92eb-93ab54bb0599",
   "metadata": {
    "id": "7e6e3793-5270-461f-92eb-93ab54bb0599"
   },
   "outputs": [],
   "source": [
    "class EfficientNetB3(ClassificationBase):\n",
    "    \n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        \n",
    "        self.network = timm.create_model('efficientnet_b3', pretrained=True)\n",
    "        num_ftrs = self.network.classifier.in_features\n",
    "        self.network.classifier = nn.Linear(num_ftrs, n_classes)\n",
    "        \n",
    "        \n",
    "    def forward(self, batch):\n",
    "        batch = batch.to(device)\n",
    "        return torch.sigmoid(self.network(batch))\n",
    "        \n",
    "        \n",
    "        \n",
    "model = EfficientNetB3()     "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ccc97d0f-f725-4229-82de-87425f6cdb09",
   "metadata": {
    "id": "ccc97d0f-f725-4229-82de-87425f6cdb09"
   },
   "outputs": [],
   "source": [
    "def fit(epochs, model, train_loader, val_loader, opt_func=torch.optim.Adam):\n",
    "    history = []\n",
    "    optimizer = opt_func(model.parameters(), 1e-5)\n",
    "    for epoch in range(epochs):\n",
    "        lrs = []\n",
    "        loss = 0\n",
    "        acc = 0\n",
    "        for batch in tqdm.tqdm(train_loader):\n",
    "            loss, acc = model.training_step(batch)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            optimizer.zero_grad()\n",
    "        print(\"Epoch [{}], loss: {:.4f}, acc: {:.4f}\".format(epoch, loss, acc))\n",
    "        result = evaluate(model, val_loader)\n",
    "        model.epoch_end(epoch, result)\n",
    "        history.append(result)\n",
    "    return history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2ae3b47-89c3-410d-a0f4-c7c58a41e5e5",
   "metadata": {
    "id": "d2ae3b47-89c3-410d-a0f4-c7c58a41e5e5"
   },
   "outputs": [],
   "source": [
    "model = model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4d4ce97-d022-4b53-959c-fff1f48b8dcc",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "f4d4ce97-d022-4b53-959c-fff1f48b8dcc",
    "outputId": "4b42f275-e432-429e-aa98-69324a8d4255"
   },
   "outputs": [],
   "source": [
    "evaluate(model, test_dataloader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9834131f-89fd-4b90-b84f-c35df6218b43",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "9834131f-89fd-4b90-b84f-c35df6218b43",
    "outputId": "62ec2a41-8486-4d95-e30f-30acc06e2773"
   },
   "outputs": [],
   "source": [
    "import tqdm\n",
    "history += fit(20, model, train_dataloader, test_dataloader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4beb8811-6ab5-4858-9ae8-bdc39f2d55d2",
   "metadata": {
    "id": "4beb8811-6ab5-4858-9ae8-bdc39f2d55d2"
   },
   "outputs": [],
   "source": [
    "torch.save(model.state_dict(), 'model_1.pth')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "B6rXE5G7oNsG",
   "metadata": {
    "id": "B6rXE5G7oNsG"
   },
   "outputs": [],
   "source": [
    "losses = []\n",
    "accs = []\n",
    "for i in range(len(history)):\n",
    "  losses.append(history[i]['val_loss'])\n",
    "  accs.append(history[i]['val_acc'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "xd0TixcXmtKP",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 283
    },
    "id": "xd0TixcXmtKP",
    "outputId": "c9d80fa0-752e-4ab2-a952-5c7bee79eb8d"
   },
   "outputs": [],
   "source": [
    "plt.plot(np.linspace(1, 30, 30).astype(int), losses)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7-iRw-JLr6XT",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 283
    },
    "id": "7-iRw-JLr6XT",
    "outputId": "2402776d-7c45-4163-8c61-8567abd6d973"
   },
   "outputs": [],
   "source": [
    "plt.plot(np.linspace(1, 30, 30).astype(int), accs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8Fei5iW6n0R9",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 287
    },
    "id": "8Fei5iW6n0R9",
    "outputId": "550c4e15-9d77-4bc1-c52e-aa1043b61e8f"
   },
   "outputs": [],
   "source": [
    "image = cv2.imread('./Data/Cataracts/102_1.jpg')\n",
    "image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
    "plt.imshow(image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cCL_Quqfr8wo",
   "metadata": {
    "id": "cCL_Quqfr8wo"
   },
   "outputs": [],
   "source": [
    "test_transforms = torchvision.transforms.Compose([\n",
    "    torchvision.transforms.ToTensor(),\n",
    "    torchvision.transforms.Resize((300, 300))\n",
    "])\n",
    "\n",
    "image = test_transforms(image)\n",
    "image = torch.reshape(image, (1, 3, 300, 300))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "PzLW9_eisCIg",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 36
    },
    "id": "PzLW9_eisCIg",
    "outputId": "23d19cdf-858b-4db5-e691-24346cf68f59"
   },
   "outputs": [],
   "source": [
    "model.eval()\n",
    "pred2label[np.argmax(model(image).cpu().detach().numpy())]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09bda199",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.load_state_dict(torch.load('model_1.pth', map_location=torch.device('cpu')))\n",
    "model"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "machine_shape": "hm",
   "name": "training.ipynb",
   "provenance": []
  },
  "gpuClass": "standard",
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "vscode": {
   "interpreter": {
    "hash": "b7b07f9a572e6bbc745eb2b53e2726eb67bcf06e62c0bc7cc634c40be74e856d"
   }
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "state": {},
    "version_major": 2,
    "version_minor": 0
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
